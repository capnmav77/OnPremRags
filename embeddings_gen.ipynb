{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the embeddings from the text files that need to be chunked and then ingested \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import ollama\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def load_text(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "            print(text[0:10000])\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please make sure {0} exists.\".format(file_path))\n",
    "        return None\n",
    "    return text \n",
    "# text = load_text(\"DataLake/magma.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text chunking with window and overlap of 500 characters \n",
    "\n",
    "def chunk_text(text, window_size=500, overlap=100):\n",
    "    \"\"\"\n",
    "    Chunk text into overlapping segments of specified window size\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to chunk\n",
    "        window_size (int): Size of each chunk in characters\n",
    "        overlap (int): Number of overlapping characters between chunks\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        # Get chunk of window_size or remaining text if shorter\n",
    "        end = min(start + window_size, len(text))\n",
    "        chunk = text[start:end]\n",
    "        \n",
    "        # Add chunk if it's not empty\n",
    "        if chunk.strip():\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "        # Move start position by window_size - overlap\n",
    "        start = start + window_size - overlap\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "# Create chunks with 500 char window and 100 char overlap\n",
    "# data_chunks = chunk_text(text, window_size=1000, overlap=200)\n",
    "\n",
    "# print(f\"Created {len(data_chunks)} chunks\")\n",
    "# print(f\"\\nFirst chunk sample:\\n{data_chunks[0][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model \n",
    "def load_model(model_name):\n",
    "    \"\"\"\n",
    "    Load a SentenceTransformer model from Hugging Face\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to load \n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "    return model\n",
    "\n",
    "# model = load_model(\"nomic-ai/CodeRankEmbed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the embedding process where the chunks that are created are embedded using the huggingface model \n",
    "\n",
    "def embed_chunks(chunks, model):\n",
    "    \"\"\"\n",
    "    Embed text chunks using the provided model\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of text chunks\n",
    "        model: SentenceTransformer model\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Array of embeddings\n",
    "    \"\"\"\n",
    "    sentences = chunks\n",
    "    embeddings = model.encode(sentences)\n",
    "    return embeddings\n",
    "\n",
    "# embeddings = embed_chunks(data_chunks,model)\n",
    "# print(embeddings)\n",
    "# similarities = model.similarity(embeddings, embeddings)\n",
    "# print(similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store \n",
    "def create_vector_store(embeddings):\n",
    "    \"\"\"\n",
    "    Create a vector store using FAISS HNSW index\n",
    "    \n",
    "    Args:\n",
    "        embeddings (np.ndarray): Array of embeddings  \n",
    "    Returns:\n",
    "        faiss.Index: HNSW Vector store\n",
    "    \"\"\"\n",
    "    # Get the dimensionality of the embeddings\n",
    "    dimension = embeddings.shape[1]\n",
    "    \n",
    "    # Create HNSW index with proper class name\n",
    "    M = 100  # Number of connections per layer\n",
    "    vector_store = faiss.IndexHNSWFlat(dimension, M)\n",
    "    \n",
    "    # Set HNSW parameters\n",
    "    vector_store.hnsw.efConstruction = 100  # Higher = more accurate but slower construction\n",
    "    vector_store.hnsw.efSearch = 100  # Higher = more accurate but slower search\n",
    "    \n",
    "    # Make sure embeddings are float32 before adding to index\n",
    "    embeddings_32 = embeddings.astype('float32')\n",
    "    \n",
    "    # Add vectors to the index\n",
    "    vector_store.add(embeddings_32)\n",
    "    print(f\"Added {len(embeddings)} vectors to HNSW index\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "# vector_store = create_vector_store(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the vector store \n",
    "def store_vector_store(vector_store, file_path):\n",
    "    \"\"\"\n",
    "    Store the vector store to a file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(vector_store, f)\n",
    "\n",
    "def load_vector_store(file_path):\n",
    "    \"\"\"\n",
    "    Load the vector store from a file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_store(query, vector_store, model, data_chunks):\n",
    "    \"\"\"\n",
    "    Query the vector store for the most similar embeddings\n",
    "    \n",
    "    Args:\n",
    "        query (str): Query to search for\n",
    "        vector_store (faiss.IndexFlatL2): Vector store to search\n",
    "        model: SentenceTransformer model\n",
    "        \n",
    "    Returns:\n",
    "        list: List of indices of the most similar embeddings\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode([query])  # get the embedding\n",
    "    query_embedding = query_embedding.astype('float32')\n",
    "    distances, indices = vector_store.search(query_embedding, k=5)\n",
    "    context = \"\"\n",
    "    for i in indices[0]:\n",
    "        context += data_chunks[i] + \"\\n\"\n",
    "    return context\n",
    "\n",
    "# query = \"merging the ss tables , how?\"\n",
    "# context = query_vector_store(query, vector_store, model, data_chunks)\n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test out the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add the context to the query for the LLM\n",
    "\n",
    "def add_context_to_query(query, context):\n",
    "    \"\"\"\n",
    "    Add context to the query for the LLM\n",
    "    \n",
    "    Args:\n",
    "        query (str): Query to add context to\n",
    "        context (str): Context to add to the query\n",
    "        \n",
    "    Returns:\n",
    "        str: Query with context added\n",
    "    \"\"\"\n",
    "    return f\"Query: {query}\\nContext: {context}\"\n",
    "\n",
    "# query_with_context = add_context_to_query(query, context)\n",
    "# print(query_with_context)\n",
    "# # now use the LLM to answer the query \n",
    "\n",
    "\n",
    "# add_context_to_query(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the query to the LLM \n",
    "def get_ollama_suggestions(query_with_context):\n",
    "    response = ollama.chat(model='deepseek-r1:14b', messages=[\n",
    "        {\n",
    "        'role': 'user',\n",
    "        'content': query_with_context\n",
    "        },\n",
    "    ],  options={\"temperature\": 0.8}, stream=True )\n",
    "    \n",
    "    for chunk in response:\n",
    "        print(chunk[\"message\"][\"content\"], end='', flush=True)\n",
    "        \n",
    "    return \"Streaming complete\"\n",
    "\n",
    "# get_ollama_suggestions(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT\n",
      "We present Magma, a write-optimized high data density key-value\n",
      "storage engine used in the Couchbase NoSQL distributed docu-\n",
      "ment database. Today’s write-heavy data-intensive applications\n",
      "like ad-serving, internet-of-things, messaging, and online gaming,\n",
      "generate massive amounts of data. As a result, the requirement\n",
      "for storing and retrieving large volumes of data has grown rapidly.\n",
      "Distributed databases that can scale out horizontally by adding\n",
      "more nodes can be used to serve the requirements of these internet-\n",
      "scale applications. To maintain a reasonable cost of ownership, we\n",
      "need to improve storage eciency in handling large data volumes\n",
      "per node, such that we don’t have to rely on adding more nodes.\n",
      "Our current generation storage engine, Couchstore is based on a\n",
      "log-structured append-only copy-on-write B+Tree architecture. To\n",
      "make substantial improvements to support higher data density and\n",
      "write throughput, we needed a storage engine architecture that\n",
      "lowers write amplication and avoids compaction operations that\n",
      "rewrite the whole database les periodically.\n",
      "We introduce Magma, a hybrid key-value storage engine that\n",
      "combines LSM Trees and a segmented log approach from log-\n",
      "structured le systems. We present a novel approach to perform-\n",
      "ing garbage collection of stale document versions avoiding index\n",
      "lookup during log segment compaction. This is the key to achieving\n",
      "storage eciency for Magma and eliminates the need for random\n",
      "I/Os during compaction. Magma oers signicantly lower write\n",
      "amplication, scalable incremental compaction, and lower space\n",
      "amplication while not regressing the read amplication. Through\n",
      "the eciency improvements, we improved the single machine data\n",
      "density supported by the Couchbase Server by 3.3x and lowered\n",
      "the memory requirement by 10x, thereby reducing the total cost\n",
      "of ownership up to 10x. Our evaluation results show that Magma\n",
      "outperforms Couchstore and RocksDB in write-heavy workloads.\n",
      "PVLDB Reference Format:\n",
      "Sarath Lakshman, Apaar Gupta, Rohan Suri, Scott Lashley, John Liang,\n",
      "Srinath Duvuru, and Ravi Mayuram. Magma: A High Data Density Storage\n",
      "Engine Used in Couchbase. PVLDB, 15(12): 3496-3508, 2022.\n",
      "doi:10.14778/3554821.3554839\n",
      "1 INTRODUCTION\n",
      "Modern-day internet-scale interactive applications generate huge\n",
      "amounts of data through user engagements. These data-intensive\n",
      "applications like ad-serving, internet-of-things, messaging, and on-\n",
      "line gaming are real-time and write-heavy, requiring large storage\n",
      "capacity and high transaction throughput. As a result, distributed\n",
      "databases that can scale horizontally have become an integral part\n",
      "of the modern data infrastructure stack that needs to operate at\n",
      "scale. The rapid growth of data volumes due to the digital wave\n",
      "has introduced challenges from a manageability and storage cost\n",
      "perspective. These problems have only grown despite the cost of\n",
      "computing and storage hardware like memory and ash dropping\n",
      "because the cost reduction has not kept up with the growth of\n",
      "data. The high throughput and storage capacity can be achieved\n",
      "by scaling out the distributed database by adding more nodes. To\n",
      "maintain a reasonable cost of ownership, we need to improve stor-\n",
      "age eciency in handling large data volumes per node, such that\n",
      "we don’t have to rely on adding more nodes.\n",
      "Under the hood, a single node of the distributed database depends\n",
      "on a persistent key-value storage engine for durable storage and\n",
      "retrieval of the database records. B+Trees [7] and Log structured\n",
      "merge trees [26] are two popular access methods for implementing\n",
      "persistent key-value storage engines. B+Tree is a read-optimized\n",
      "data structure while LSM Tree is write-optimized. Both of these\n",
      "data structures can be found in popular distributed databases like\n",
      "Couchbase, Cassandra, MongoDB, CockroachDB, etc. The eciency\n",
      "and performance of I/O intensive index structures are essentially a\n",
      "balance among three properties. Write amplication, read ampli-\n",
      "cation, and space amplication (RUM Conjecture) [4]. We cannot\n",
      "achieve write-optimized, read-optimized, and space-optimized per-\n",
      "sistent index structures all at the same time. Write amplication\n",
      "denes the ratio of the amount of data written to disk for every byte\n",
      "of write to the storage engine. Read amplication is the number\n",
      "of reads issued to the disk for every read operation of the storage\n",
      "engine. Space amplication is the ratio of the amount of data stored\n",
      "on a disk to the user input data size.\n",
      "Key Challenges with High Data Density. We start by identify-\n",
      "ing the challenges faced by our append-only copy-on-write B+Tree\n",
      "based storage engine to sustain high write throughput with a large\n",
      "volume of data per node with a database size to memory ratio of\n",
      "100x.\n",
      "Slow Writes. Updates in a copy-on-write B+Tree are done as\n",
      "read-modify-write, requiring random read I/Os. As the density\n",
      "increases, reads incur large cache misses for the B+Tree pages.\n",
      "Keys are spread out in a large key range distribution, and hence\n",
      "larger B+Tree. The opportunity for deduplication before writing\n",
      "and amortization of page rewrites due to large batches reduces,\n",
      "thereby increasing the write amplication. Write latency increases\n",
      "and throughput drops.\n",
      "Compaction Challenges. When the database becomes frag-\n",
      "mented, a compaction operation needs to be performed to limit\n",
      "space amplication. Compaction performs a full database rewrite\n",
      "This work is licensed under the Creative Commons BY-NC-ND 4.0 International\n",
      "License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\n",
      "this license. For any use beyond those covered by this license, obtain permission by\n",
      "emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\n",
      "licensed to the VLDB Endowment.\n",
      "Proceedings of the VLDB Endowment, Vol. 15, No. 12 ISSN 2150-8097.\n",
      "doi:10.14778/3554821.3554839\n",
      "3496\n",
      "by copying live documents to a new le and building the B+Tree\n",
      "indexes, taking time proportional to the database size. After copy-\n",
      "ing, it has to run catchup to replay the extra changes that came\n",
      "in during the copying. This introduces high write amplication.\n",
      "Writes can only run at the speed of single-threaded compaction\n",
      "per DB le. Even though we have several DB les per node, as the\n",
      "density increases, the size of individual les increases. Full DB le\n",
      "rewrite and longer duration catchup with larger DB size are no\n",
      "longer scalable.\n",
      "We present Magma, a hybrid write-optimized storage engine\n",
      "based on LSM Trees [26] and Log-structured storage [28] available\n",
      "in Couchbase 7.1. In this paper, we describe the following key\n",
      "contributions:\n",
      "• Evaluation of copy-on-write B+ tree for high data density\n",
      "• Design of a high data density storage engine that blends\n",
      "LSM Trees with Log-Structured storage to achieve low write\n",
      "amplication\n",
      "• A novel method for garbage collecting the log-structured\n",
      "storage eciently\n",
      "This paper is organized into three parts. We initially discuss the\n",
      "background by providing details on B+Trees in the context of chal-\n",
      "lenges faced by our existing storage engine Couchstore in Section\n",
      "2. Section 3 and 4 discuss the Magma design and our contributions.\n",
      "Section 9 provides experimental evaluation results and discussion.\n",
      "Couchbase distributed database has a microservices approach\n",
      "called multi-dimensional-scaling [6, 9] to horizontally scale all parts\n",
      "of the database. Data service is a distributed high-performance,\n",
      "replicated and elastic key-value document storage service that\n",
      "spans across several nodes as shown in Figure 1. In Couchbase\n",
      "Figure 2: Copy-on-write B+Tree undergoing a modication\n",
      "Couchstore [10] is the current generation storage engine of\n",
      "Couchbase Server for document storage. The overall architecture\n",
      "3497\n",
      "inherits from the storage model of Apache CouchDB [2]. This stor-\n",
      "age engine is battle-hardened in production and has been serving\n",
      "Couchbase customers for almost 10 years. Couchstore is based\n",
      "on copy-on-write (COW) B+Tree and it follows a log-structured\n",
      "append-only storage model. Each vBucket maintains a couchstore\n",
      "le and stores the documents belonging to the vBucket. The le\n",
      "format consists of documents and B+Tree pages interleaved in the\n",
      "le. Each couchstore le maintains three B+Trees, a byKey index\n",
      "for accessing by key, bySeqno index for accessing by seqno, and a\n",
      "metadata B+Tree for storing vBucket statistics and metadata. To\n",
      "look up a document by key, byKey B+Tree is used to obtain the\n",
      "le oset of the document version, and a read is performed from\n",
      "the oset. Couchstore does not have a dedicated managed cache.\n",
      "Rather it depends on the le system buer cache.\n",
      "A copy-on-write B+Tree is an adaptation of B+Tree for the log-\n",
      "structured storage model. Compared to update in-place B+trees, the\n",
      "COW B+Trees can achieve higher write throughput as it performs\n",
      "writes in a sequential access pattern. B+Tree consists of intermedi-\n",
      "ate pages and leaf pages. The leaf page consists of key-record pairs.\n",
      "Intermediate pages consist of key-value pairs with the value being\n",
      "the le osets of pointing pages within the same le.\n",
      "2.2.1 Write Operation. B+Tree modication involves a read-modify-\n",
      "write scheme for the B+Tree page. When a record needs to be added\n",
      "or removed to the COW B+Tree, it locates the leaf page where the\n",
      "record key belongs by traversing the tree from the root page and\n",
      "navigating through the intermediate pages. It makes a copy of the\n",
      "leaf page in memory and modies the page to add or remove the\n",
      "record. The new version of the page is appended to the DB le. Now\n",
      "that the location of the leaf page has changed to a new oset, we\n",
      "need to update the intermediate node that points to the leaf node.\n",
      "Similarly, all the intermediate pages up to the root page need to be\n",
      "rewritten to update the new page locations. As shown in Figure\n",
      "2, if a record is modied or added to page C3, it has to make the\n",
      "modication in C3 and create C3’. Similarly, the pointing parent\n",
      "pages including the intermediate page B2’ and new page A’ need\n",
      "to be written. The older version of the pages (C3, B2, A) become\n",
      "Created 21 chunks\n",
      "\n",
      "First chunk sample:\n",
      "ABSTRACT\n",
      "We present Magma, a write-optimized high data density key-value\n",
      "storage engine used in the Couchbase NoSQL distributed docu-\n",
      "ment database. Today’s write-heavy data-intensive applications\n",
      "lik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19513035  1.0389959  -0.6033782  ... -0.22977789  0.12080007\n",
      "   0.56734395]\n",
      " [ 0.5073284  -0.37393796 -0.7079576  ... -0.23452719  1.4435698\n",
      "   0.2964999 ]\n",
      " [ 0.2933281   1.4403888  -0.6809826  ... -0.07078546  0.87308353\n",
      "   0.9864548 ]\n",
      " ...\n",
      " [ 0.60976076  0.2126527  -0.59666383 ...  0.22752672  0.62414616\n",
      "   0.21837918]\n",
      " [ 0.2967483   0.15918534 -0.6006259  ...  0.16863205  0.92862195\n",
      "  -1.0542966 ]\n",
      " [ 0.9830756   1.2716196  -0.39954367 ... -0.49186674 -0.32120115\n",
      "  -1.3642838 ]]\n",
      "torch.Size([21, 21])\n",
      "Added 21 vectors to HNSW index\n",
      "e the cost of reads as well as reduce space usage, we have\n",
      "to periodically merge SSTable les and reclaim space. This process\n",
      "is called compaction.\n",
      "A level-based compaction strategy popularized by LevelDB [15,\n",
      "24] is a common compaction strategy for achieving lower read am-\n",
      "plication and space amplication. The LSM Tree is organized into\n",
      "multiple levels of exponentially increasing sizes with the smallest\n",
      "size at the top and the largest being the bottom level. Each level can\n",
      "have several SSTable les. The in-memory component is periodi-\n",
      "cally ushed into level-0 as an SSTable le. Level-0 is a special level\n",
      "that accumulates new data. It can have multiple SSTables with over-\n",
      "lapping key ranges. All other higher levels have non-overlapping\n",
      "key ranges between the SSTables in the level. Each non-level-0 level\n",
      "has a contiguous key range. When level-0 reaches a size threshold,\n",
      "the SSTable les are picked and merged with sstables from the\n",
      "level-1 and the overlapping key range from the level-1\n",
      " where n is the number of\n",
      "items in the SSTable. This can be expensive in terms of CPU andI/O\n",
      "operations.\n",
      "To optimize the lookup, LSM Trees generally maintain a bloom\n",
      "lter per SSTable with high accuracy. This avoids I/O reads from\n",
      "SSTables which do not have the key. Using a bloom-lter with high\n",
      "accuracy, it can service the lookup operation using a single SSTable\n",
      "or a single B+Tree. This makes the cost of lookup similar to that of\n",
      "a traditional B+Tree\n",
      "te-ahead log. The in-memory component uses a sort ordered\n",
      "data structure providing fast lookups and range reads. Once the\n",
      "in-memory component reaches a threshold size limit, it is frozen\n",
      "and a new one is initialized for processing incoming writes. The\n",
      "records from the frozen in-memory component are converted into\n",
      "a B+Tree on a new le. This le is called a sorted strings table\n",
      "(SSTable).\n",
      "2.3.2 Compaction Operation. As the in-memory components are\n",
      "ushed to the disk, more SSTable les are generated. For performing\n",
      "a lookup, it has to search SSTables in the most recent table rst order\n",
      "until the key is found. The I/O and CPU cost becomes proportional\n",
      "3498\n",
      "to the number of tables to be evaluated. A large number of tables\n",
      "also consume space as they may contain stale key-value pairs. To\n",
      "minimize the cost of reads as well as reduce space usage, we have\n",
      "to periodically merge SSTable les and reclaim space. This process\n",
      "is called compaction.\n",
      "A level-based compaction strategy popularized by Lev\n",
      "on-level-0 level\n",
      "has a contiguous key range. When level-0 reaches a size threshold,\n",
      "the SSTable les are picked and merged with sstables from the\n",
      "level-1 and the overlapping key range from the level-1 is replaced\n",
      "with new SSTable les. This involves a k-way merge sort between\n",
      "the source SSTable les. A similar process is followed to manage\n",
      "the size of each level according to the size threshold.\n",
      "Due to the compactions that periodically rewrite the data, LSM\n",
      "Trees can incur high write amplication. For an LSM Tree with a\n",
      "10x level multiplier, each level except the level-0 contributes a write\n",
      "amplication of 10. When data is ushed to level-0 from the write\n",
      "cache, it contributes to a write amplication of 1. Similarly, the\n",
      "write-ahead log also contributes a write amplication of 1. Hence,\n",
      "for an LSM Tree with 5 levels, the worst-case write amplication\n",
      "can go up to 42. For skewed workloads, observed write amplication\n",
      "will be lower than the worst-case amplication.\n",
      "2.3.3 Read Operation. T\n",
      " B+Tree bulk load operation\n",
      "to the new le, rebuilding the B+Tree. While the compaction is\n",
      "running, the writes continue to operate on the DB le. The com-\n",
      "pactor operates on a point-in-time snapshot of the B+Tree. After\n",
      "nishing the B+Tree bulk load, it runs a catchup phase to replay\n",
      "the new additions/deletions that happened to the B+Tree from the\n",
      "point-in-time version used by the compactor up to the latest B+Tree\n",
      "in the DB le. On completion of the catchup phase, the old DB le\n",
      "is removed and writers and readers switch to the new DB le. The\n",
      "space is reclaimed. Compaction is a single-threaded process that\n",
      "runs on a DB le.\n",
      "2.3 Log-Structured Merge Tree\n",
      "Figure 3: LSM Tree architecture\n",
      "LSM Tree is a write-optimized persistent index data structure.\n",
      "LSM Trees achieve high write throughput by utilizing superior\n",
      "sequential write bandwidth of SSDs [18] and spinning disks com-\n",
      "pared to the random I/O access pattern. The large sequential writes\n",
      "are achieved by batching a large number of mutati\n",
      "\n",
      "Query: merging the ss tables , how?\n",
      "Context: e the cost of reads as well as reduce space usage, we have\n",
      "to periodically merge SSTable les and reclaim space. This process\n",
      "is called compaction.\n",
      "A level-based compaction strategy popularized by LevelDB [15,\n",
      "24] is a common compaction strategy for achieving lower read am-\n",
      "plication and space amplication. The LSM Tree is organized into\n",
      "multiple levels of exponentially increasing sizes with the smallest\n",
      "size at the top and the largest being the bottom level. Each level can\n",
      "have several SSTable les. The in-memory component is periodi-\n",
      "cally ushed into level-0 as an SSTable le. Level-0 is a special level\n",
      "that accumulates new data. It can have multiple SSTables with over-\n",
      "lapping key ranges. All other higher levels have non-overlapping\n",
      "key ranges between the SSTables in the level. Each non-level-0 level\n",
      "has a contiguous key range. When level-0 reaches a size threshold,\n",
      "the SSTable les are picked and merged with sstables from the\n",
      "level-1 and the overlapping key range from the level-1\n",
      " where n is the number of\n",
      "items in the SSTable. This can be expensive in terms of CPU andI/O\n",
      "operations.\n",
      "To optimize the lookup, LSM Trees generally maintain a bloom\n",
      "lter per SSTable with high accuracy. This avoids I/O reads from\n",
      "SSTables which do not have the key. Using a bloom-lter with high\n",
      "accuracy, it can service the lookup operation using a single SSTable\n",
      "or a single B+Tree. This makes the cost of lookup similar to that of\n",
      "a traditional B+Tree\n",
      "te-ahead log. The in-memory component uses a sort ordered\n",
      "data structure providing fast lookups and range reads. Once the\n",
      "in-memory component reaches a threshold size limit, it is frozen\n",
      "and a new one is initialized for processing incoming writes. The\n",
      "records from the frozen in-memory component are converted into\n",
      "a B+Tree on a new le. This le is called a sorted strings table\n",
      "(SSTable).\n",
      "2.3.2 Compaction Operation. As the in-memory components are\n",
      "ushed to the disk, more SSTable les are generated. For performing\n",
      "a lookup, it has to search SSTables in the most recent table rst order\n",
      "until the key is found. The I/O and CPU cost becomes proportional\n",
      "3498\n",
      "to the number of tables to be evaluated. A large number of tables\n",
      "also consume space as they may contain stale key-value pairs. To\n",
      "minimize the cost of reads as well as reduce space usage, we have\n",
      "to periodically merge SSTable les and reclaim space. This process\n",
      "is called compaction.\n",
      "A level-based compaction strategy popularized by Lev\n",
      "on-level-0 level\n",
      "has a contiguous key range. When level-0 reaches a size threshold,\n",
      "the SSTable les are picked and merged with sstables from the\n",
      "level-1 and the overlapping key range from the level-1 is replaced\n",
      "with new SSTable les. This involves a k-way merge sort between\n",
      "the source SSTable les. A similar process is followed to manage\n",
      "the size of each level according to the size threshold.\n",
      "Due to the compactions that periodically rewrite the data, LSM\n",
      "Trees can incur high write amplication. For an LSM Tree with a\n",
      "10x level multiplier, each level except the level-0 contributes a write\n",
      "amplication of 10. When data is ushed to level-0 from the write\n",
      "cache, it contributes to a write amplication of 1. Similarly, the\n",
      "write-ahead log also contributes a write amplication of 1. Hence,\n",
      "for an LSM Tree with 5 levels, the worst-case write amplication\n",
      "can go up to 42. For skewed workloads, observed write amplication\n",
      "will be lower than the worst-case amplication.\n",
      "2.3.3 Read Operation. T\n",
      " B+Tree bulk load operation\n",
      "to the new le, rebuilding the B+Tree. While the compaction is\n",
      "running, the writes continue to operate on the DB le. The com-\n",
      "pactor operates on a point-in-time snapshot of the B+Tree. After\n",
      "nishing the B+Tree bulk load, it runs a catchup phase to replay\n",
      "the new additions/deletions that happened to the B+Tree from the\n",
      "point-in-time version used by the compactor up to the latest B+Tree\n",
      "in the DB le. On completion of the catchup phase, the old DB le\n",
      "is removed and writers and readers switch to the new DB le. The\n",
      "space is reclaimed. Compaction is a single-threaded process that\n",
      "runs on a DB le.\n",
      "2.3 Log-Structured Merge Tree\n",
      "Figure 3: LSM Tree architecture\n",
      "LSM Tree is a write-optimized persistent index data structure.\n",
      "LSM Trees achieve high write throughput by utilizing superior\n",
      "sequential write bandwidth of SSDs [18] and spinning disks com-\n",
      "pared to the random I/O access pattern. The large sequential writes\n",
      "are achieved by batching a large number of mutati\n",
      "\n",
      "<think>\n",
      "Okay, so I'm trying to understand how merging SSTables works in an LSM Tree. From what I gather, the context is about LevelDB's level-based compaction strategy. Let me break this down step by step.\n",
      "\n",
      "First, I know that LSM Trees use multiple levels of SSTables to organize data, with each level having a larger size than the previous one. The idea is to minimize read amplification and space usage by periodically merging these tables.\n",
      "\n",
      "So, when data comes in, it's stored in memory until it reaches a certain threshold, then it's flushed to disk as an SSTable at level 0. Level 0 can have multiple tables with overlapping key ranges because it's the newest data. As more data is written, eventually level 0 gets too big, and compaction kicks in.\n",
      "\n",
      "The process of merging starts here. I think the first step is that some SSTables from level 0 are selected to be merged with those in level 1. But how exactly does this happen? It mentions a k-way merge sort between the source SSTables. So, if we have multiple tables in both level 0 and level 1, they all get involved in the merge.\n",
      "\n",
      "Wait, but I'm not entirely sure about the order. Do they take one table from level 0 and one from level 1 at a time? Or do they merge all of them together? The mention of k-way suggests that it's merging multiple tables at once, which makes sense for efficiency.\n",
      "\n",
      "After merging, these new SSTables replace the overlapping ones in level 1. So, the merged data is now in level 1 as newer, non-overlapping tables. This must help because higher levels have non-overlapping key ranges, making lookups more efficient since you don't have to check multiple tables for a single key.\n",
      "\n",
      "I'm also trying to visualize how this affects read operations. Before compaction, when looking up a key, the system might have to check several SSTables across different levels, which is slow. After compaction, since higher levels have fewer, larger tables with non-overlapping keys, lookups become faster because they can pinpoint the exact table(s) that might contain the key.\n",
      "\n",
      "But I'm a bit confused about the write amplification part. It says each level contributes to it based on the multiplier, and for 5 levels, it's up to 42 in the worst case. That seems high. So every time data is moved from one level to another during compaction, it's writing multiple times, which increases the total writes beyond the initial data size.\n",
      "\n",
      "Also, the fact that compaction is a single-threaded process might be a bottleneck. If the system has a lot of data or slow disks, this could really slow things down because only one part of the merge can happen at a time.\n",
      "\n",
      "Putting it all together, the merging process seems crucial for maintaining efficient operations in an LSM Tree. It helps reduce read costs by minimizing the number of tables that need to be checked during lookups and frees up space by removing redundant or old data. However, this comes with trade-offs in terms of increased write operations and potential performance bottlenecks during compaction.\n",
      "\n",
      "I'm still not entirely clear on how exactly the k-way merge works in practice. Does it involve reading all the SSTables into memory first, sorting them, and then writing back? Or is it done in a more stream-like fashion where data is written sequentially without holding everything in memory? I think it's probably a block-wise merge to manage memory efficiently.\n",
      "\n",
      "Another thing I'm curious about is how the system decides which tables to merge. It mentions size thresholds, but what metrics are used beyond just size? Maybe the number of tables or the age of the data could also play a role. Also, how often does compaction happen? Is it triggered by reaching certain memory usage in level 0, or is it scheduled periodically?\n",
      "\n",
      "I'm also thinking about the impact of different workload types on compaction. Skewed workloads might have patterns that make some keys more popular than others, affecting how data is distributed across levels and how often they need to be merged.\n",
      "\n",
      "Overall, merging SSTables through level-based compaction seems like a balance between efficiently managing storage and maintaining good performance for read and write operations. It's a critical process that ensures the LSM Tree remains effective, but it requires careful implementation to avoid becoming a bottleneck.\n",
      "</think>\n",
      "\n",
      "Merging SSTables in an LSM Tree involves a systematic approach to maintain efficient data management. Here's a structured explanation of the process and its implications:\n",
      "\n",
      "### Key Steps in Merging SSTables:\n",
      "1. **Data Flushing**: New data is stored in memory until it reaches a threshold, then flushed to disk as an SSTable at level 0, which allows overlapping key ranges.\n",
      "\n",
      "2. **Compaction Triggers**: When level 0 becomes too large (based on size or number of tables), compaction is triggered to merge tables from level 0 with those in level 1.\n",
      "\n",
      "3. **Merge Process**:\n",
      "   - **k-way Merge Sort**: Multiple SSTables (from levels 0 and 1) are merged simultaneously, likely in a block-wise manner to manage memory efficiently.\n",
      "   - **Resulting Tables**: The merged data forms new SSTables at level 1 with non-overlapping key ranges, improving lookup efficiency.\n",
      "\n",
      "### Impact on Operations:\n",
      "- **Read Efficiency**: Post-compaction, lookups become faster as keys can be located in fewer, non-overlapping tables.\n",
      "- **Write Amplification**: Each compaction iteration increases write operations, potentially leading to high write amplification (e.g., up to 42 for 5 levels), affecting performance.\n",
      "\n",
      "### Considerations and Trade-offs:\n",
      "- **Bottlenecks**: Single-threaded compaction can be a bottleneck on systems with slow disks or large datasets.\n",
      "- **Merge Mechanism**: Likely involves reading SSTables into memory, sorting, and writing sequentially, without holding all data in memory.\n",
      "- **Compaction Decision Factors**: Triggers include size and possibly number of tables; scheduling might involve memory usage monitoring.\n",
      "- **Workload Impact**: Skewed workloads affect data distribution and compaction frequency, influencing system performance.\n",
      "\n",
      "### Conclusion:\n",
      "Merging SSTables through level-based compaction is crucial for maintaining efficient storage and performance in LSM Trees. While it optimizes reads and space, it requires careful management to avoid becoming a bottleneck, balancing between efficient storage and operational efficiency."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Streaming complete'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = load_text(\"DataLake/magma.txt\")\n",
    "# Create chunks with 500 char window and 100 char overlap\n",
    "data_chunks = chunk_text(text, window_size=1000, overlap=200)\n",
    "\n",
    "print(f\"Created {len(data_chunks)} chunks\")\n",
    "print(f\"\\nFirst chunk sample:\\n{data_chunks[0][:200]}...\")\n",
    "\n",
    "model = load_model(\"nomic-ai/CodeRankEmbed\")\n",
    "\n",
    "embeddings = embed_chunks(data_chunks,model)\n",
    "print(embeddings)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "\n",
    "vector_store = create_vector_store(embeddings)\n",
    "store_vector_store(vector_store=vector_store, file_path=\"VectorStore/magma.pkl\")\n",
    "\n",
    "vector_store = load_vector_store(file_path=\"VectorStore/magma.pkl\")\n",
    "query = \"merging the ss tables , how?\"\n",
    "context = query_vector_store(query, vector_store, model, data_chunks)\n",
    "print(context)\n",
    "\n",
    "query_with_context = add_context_to_query(query, context)\n",
    "print(query_with_context)\n",
    "# now use the LLM to answer the query \n",
    "\n",
    "\n",
    "add_context_to_query(query, context)\n",
    "\n",
    "get_ollama_suggestions(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT\n",
      "We present Magma, a write-optimized high data density key-value\n",
      "storage engine used in the Couchbase NoSQL distributed docu-\n",
      "ment database. Today’s write-heavy data-intensive applications\n",
      "like ad-serving, internet-of-things, messaging, and online gaming,\n",
      "generate massive amounts of data. As a result, the requirement\n",
      "for storing and retrieving large volumes of data has grown rapidly.\n",
      "Distributed databases that can scale out horizontally by adding\n",
      "more nodes can be used to serve the requirements of these internet-\n",
      "scale applications. To maintain a reasonable cost of ownership, we\n",
      "need to improve storage eciency in handling large data volumes\n",
      "per node, such that we don’t have to rely on adding more nodes.\n",
      "Our current generation storage engine, Couchstore is based on a\n",
      "log-structured append-only copy-on-write B+Tree architecture. To\n",
      "make substantial improvements to support higher data density and\n",
      "write throughput, we needed a storage engine architecture that\n",
      "lowers write amplica\n",
      " while not regressing the read amplication. Through\n",
      "the eciency improvements, we improved the single machine data\n",
      "density supported by the Couchbase Server by 3.3x and lowered\n",
      "the memory requirement by 10x, thereby reducing the total cost\n",
      "of ownership up to 10x. Our evaluation results show that Magma\n",
      "outperforms Couchstore and RocksDB in write-heavy workloads.\n",
      "PVLDB Reference Format:\n",
      "Sarath Lakshman, Apaar Gupta, Rohan Suri, Scott Lashley, John Liang,\n",
      "Srinath Duvuru, and Ravi Mayuram. Magma: A High Data Density Storage\n",
      "Engine Used in Couchbase. PVLDB, 15(12): 3496-3508, 2022.\n",
      "doi:10.14778/3554821.3554839\n",
      "1 INTRODUCTION\n",
      "Modern-day internet-scale interactive applications generate huge\n",
      "amounts of data through user engagements. These data-intensive\n",
      "applications like ad-serving, internet-of-things, messaging, and on-\n",
      "line gaming are real-time and write-heavy, requiring large storage\n",
      "capacity and high transaction throughput. As a result, distributed\n",
      "databases that can scale horizontally ha\n",
      " append-only copy-on-write B+Tree architecture. To\n",
      "make substantial improvements to support higher data density and\n",
      "write throughput, we needed a storage engine architecture that\n",
      "lowers write amplication and avoids compaction operations that\n",
      "rewrite the whole database les periodically.\n",
      "We introduce Magma, a hybrid key-value storage engine that\n",
      "combines LSM Trees and a segmented log approach from log-\n",
      "structured le systems. We present a novel approach to perform-\n",
      "ing garbage collection of stale document versions avoiding index\n",
      "lookup during log segment compaction. This is the key to achieving\n",
      "storage eciency for Magma and eliminates the need for random\n",
      "I/Os during compaction. Magma oers signicantly lower write\n",
      "amplication, scalable incremental compaction, and lower space\n",
      "amplication while not regressing the read amplication. Through\n",
      "the eciency improvements, we improved the single machine data\n",
      "density supported by the Couchbase Server by 3.3x and lowered\n",
      "the memory requirement\n",
      ", obtain permission by\n",
      "emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\n",
      "licensed to the VLDB Endowment.\n",
      "Proceedings of the VLDB Endowment, Vol. 15, No. 12 ISSN 2150-8097.\n",
      "doi:10.14778/3554821.3554839\n",
      "3496\n",
      "by copying live documents to a new le and building the B+Tree\n",
      "indexes, taking time proportional to the database size. After copy-\n",
      "ing, it has to run catchup to replay the extra changes that came\n",
      "in during the copying. This introduces high write amplication.\n",
      "Writes can only run at the speed of single-threaded compaction\n",
      "per DB le. Even though we have several DB les per node, as the\n",
      "density increases, the size of individual les increases. Full DB le\n",
      "rewrite and longer duration catchup with larger DB size are no\n",
      "longer scalable.\n",
      "We present Magma, a hybrid write-optimized storage engine\n",
      "based on LSM Trees [26] and Log-structured storage [28] available\n",
      "in Couchbase 7.1. In this paper, we describe the following key\n",
      "contributions:\n",
      "• Evaluation of cop\n",
      "\n",
      "age eciency in handling large data volumes per node, such that\n",
      "we don’t have to rely on adding more nodes.\n",
      "Under the hood, a single node of the distributed database depends\n",
      "on a persistent key-value storage engine for durable storage and\n",
      "retrieval of the database records. B+Trees [7] and Log structured\n",
      "merge trees [26] are two popular access methods for implementing\n",
      "persistent key-value storage engines. B+Tree is a read-optimized\n",
      "data structure while LSM Tree is write-optimized. Both of these\n",
      "data structures can be found in popular distributed databases like\n",
      "Couchbase, Cassandra, MongoDB, CockroachDB, etc. The eciency\n",
      "and performance of I/O intensive index structures are essentially a\n",
      "balance among three properties. Write amplication, read ampli-\n",
      "cation, and space amplication (RUM Conjecture) [4]. We cannot\n",
      "achieve write-optimized, read-optimized, and space-optimized per-\n",
      "sistent index structures all at the same time. Write amplication\n",
      "denes the ratio of the amount of data writ\n",
      "\n",
      "Query: what's the use of magma \n",
      "Context: ABSTRACT\n",
      "We present Magma, a write-optimized high data density key-value\n",
      "storage engine used in the Couchbase NoSQL distributed docu-\n",
      "ment database. Today’s write-heavy data-intensive applications\n",
      "like ad-serving, internet-of-things, messaging, and online gaming,\n",
      "generate massive amounts of data. As a result, the requirement\n",
      "for storing and retrieving large volumes of data has grown rapidly.\n",
      "Distributed databases that can scale out horizontally by adding\n",
      "more nodes can be used to serve the requirements of these internet-\n",
      "scale applications. To maintain a reasonable cost of ownership, we\n",
      "need to improve storage eciency in handling large data volumes\n",
      "per node, such that we don’t have to rely on adding more nodes.\n",
      "Our current generation storage engine, Couchstore is based on a\n",
      "log-structured append-only copy-on-write B+Tree architecture. To\n",
      "make substantial improvements to support higher data density and\n",
      "write throughput, we needed a storage engine architecture that\n",
      "lowers write amplica\n",
      " while not regressing the read amplication. Through\n",
      "the eciency improvements, we improved the single machine data\n",
      "density supported by the Couchbase Server by 3.3x and lowered\n",
      "the memory requirement by 10x, thereby reducing the total cost\n",
      "of ownership up to 10x. Our evaluation results show that Magma\n",
      "outperforms Couchstore and RocksDB in write-heavy workloads.\n",
      "PVLDB Reference Format:\n",
      "Sarath Lakshman, Apaar Gupta, Rohan Suri, Scott Lashley, John Liang,\n",
      "Srinath Duvuru, and Ravi Mayuram. Magma: A High Data Density Storage\n",
      "Engine Used in Couchbase. PVLDB, 15(12): 3496-3508, 2022.\n",
      "doi:10.14778/3554821.3554839\n",
      "1 INTRODUCTION\n",
      "Modern-day internet-scale interactive applications generate huge\n",
      "amounts of data through user engagements. These data-intensive\n",
      "applications like ad-serving, internet-of-things, messaging, and on-\n",
      "line gaming are real-time and write-heavy, requiring large storage\n",
      "capacity and high transaction throughput. As a result, distributed\n",
      "databases that can scale horizontally ha\n",
      " append-only copy-on-write B+Tree architecture. To\n",
      "make substantial improvements to support higher data density and\n",
      "write throughput, we needed a storage engine architecture that\n",
      "lowers write amplication and avoids compaction operations that\n",
      "rewrite the whole database les periodically.\n",
      "We introduce Magma, a hybrid key-value storage engine that\n",
      "combines LSM Trees and a segmented log approach from log-\n",
      "structured le systems. We present a novel approach to perform-\n",
      "ing garbage collection of stale document versions avoiding index\n",
      "lookup during log segment compaction. This is the key to achieving\n",
      "storage eciency for Magma and eliminates the need for random\n",
      "I/Os during compaction. Magma oers signicantly lower write\n",
      "amplication, scalable incremental compaction, and lower space\n",
      "amplication while not regressing the read amplication. Through\n",
      "the eciency improvements, we improved the single machine data\n",
      "density supported by the Couchbase Server by 3.3x and lowered\n",
      "the memory requirement\n",
      ", obtain permission by\n",
      "emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\n",
      "licensed to the VLDB Endowment.\n",
      "Proceedings of the VLDB Endowment, Vol. 15, No. 12 ISSN 2150-8097.\n",
      "doi:10.14778/3554821.3554839\n",
      "3496\n",
      "by copying live documents to a new le and building the B+Tree\n",
      "indexes, taking time proportional to the database size. After copy-\n",
      "ing, it has to run catchup to replay the extra changes that came\n",
      "in during the copying. This introduces high write amplication.\n",
      "Writes can only run at the speed of single-threaded compaction\n",
      "per DB le. Even though we have several DB les per node, as the\n",
      "density increases, the size of individual les increases. Full DB le\n",
      "rewrite and longer duration catchup with larger DB size are no\n",
      "longer scalable.\n",
      "We present Magma, a hybrid write-optimized storage engine\n",
      "based on LSM Trees [26] and Log-structured storage [28] available\n",
      "in Couchbase 7.1. In this paper, we describe the following key\n",
      "contributions:\n",
      "• Evaluation of cop\n",
      "\n",
      "age eciency in handling large data volumes per node, such that\n",
      "we don’t have to rely on adding more nodes.\n",
      "Under the hood, a single node of the distributed database depends\n",
      "on a persistent key-value storage engine for durable storage and\n",
      "retrieval of the database records. B+Trees [7] and Log structured\n",
      "merge trees [26] are two popular access methods for implementing\n",
      "persistent key-value storage engines. B+Tree is a read-optimized\n",
      "data structure while LSM Tree is write-optimized. Both of these\n",
      "data structures can be found in popular distributed databases like\n",
      "Couchbase, Cassandra, MongoDB, CockroachDB, etc. The eciency\n",
      "and performance of I/O intensive index structures are essentially a\n",
      "balance among three properties. Write amplication, read ampli-\n",
      "cation, and space amplication (RUM Conjecture) [4]. We cannot\n",
      "achieve write-optimized, read-optimized, and space-optimized per-\n",
      "sistent index structures all at the same time. Write amplication\n",
      "denes the ratio of the amount of data writ\n",
      "\n",
      "<think>\n",
      "Okay, so I'm trying to understand what Magma is and why it's useful based on the context provided. Let me break this down step by step.\n",
      "\n",
      "First, I know that Magma is a storage engine used in Couchbase, which is a NoSQL database. From the abstract, it says that Magma is write-optimized and has high data density. It's designed for applications like ad-serving, IoT, messaging, and online gaming, which generate a lot of data quickly.\n",
      "\n",
      "The context mentions that these applications require handling massive amounts of data efficiently because they're write-heavy. Traditional storage engines in Couchbase use something called a B+Tree architecture, but apparently, this has some issues with scaling and efficiency when dealing with large volumes of data.\n",
      "\n",
      "I remember reading somewhere that B+Trees are good for read-heavy operations, but writes can be problematic because they might require more I/O operations or cause higher write amplification. The article talks about how the current engine, Couchstore, uses a log-structured append-only copy-on-write B+Tree. But this approach leads to problems like full database file rewrites and longer catchup times as data grows.\n",
      "\n",
      "So, Magma was introduced to address these issues. It's described as a hybrid key-value storage engine that combines LSM Trees (Log-Structured Merge Trees) and a segmented log approach from log-structured filesystems. I think LSM Trees are better for write-heavy workloads because they can handle inserts more efficiently without having to rewrite the entire data structure.\n",
      "\n",
      "The context explains that Magma avoids compaction operations by using garbage collection of stale document versions during log segment compaction without needing index lookups. This reduces random I/O, which is a big plus for performance and efficiency.\n",
      "\n",
      "Key improvements with Magma include lower write amplification, scalable incremental compaction, and lower space amplification without sacrificing read performance. These changes have significantly increased data density per node by 3.3x and reduced memory requirements by 10x, leading to a 10x reduction in total cost of ownership.\n",
      "\n",
      "So putting it all together, Magma's main uses seem to be optimizing for high write throughput, improving storage efficiency, reducing operational costs, and scaling better with the same number of nodes compared to previous engines like Couchstore. It's particularly useful for large-scale applications that generate a lot of data quickly and require efficient storage solutions without needing constant infrastructure expansion.\n",
      "</think>\n",
      "\n",
      "Magma is a storage engine designed by Couchbase to address the challenges faced by write-heavy, large-scale applications such as those in ad-serving, IoT, messaging, and online gaming. It offers several key advantages:\n",
      "\n",
      "1. **Write Optimization**: Magma is optimized for high write throughput, making it ideal for applications that generate massive amounts of data quickly.\n",
      "\n",
      "2. **Efficient Storage**: By combining LSM Trees and a segmented log approach, Magma efficiently manages storage, reducing the need for random I/O during compaction and lowering write amplification.\n",
      "\n",
      "3. **Scalability**: It improves scalability by supporting higher data density (3.3x improvement) and reducing memory requirements (10x reduction), thus enhancing performance without increasing infrastructure.\n",
      "\n",
      "4. **Cost Efficiency**: The lower memory and storage demands of Magma lead to a significant reduction in the total cost of ownership, making it a cost-effective solution for scaling database needs.\n",
      "\n",
      "5. **Reduced Operational Complexity**: By avoiding full database file rewrites and minimizing compaction overhead, Magma simplifies operations and maintains efficient performance as data scales.\n",
      "\n",
      "In summary, Magma is crucial for applications needing efficient storage solutions that can handle high write volumes without compromising on scalability or cost-effectiveness."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Streaming complete'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what's the use of magma \"\n",
    "context = query_vector_store(query, vector_store, model, data_chunks)\n",
    "print(context)\n",
    "\n",
    "query_with_context = add_context_to_query(query, context)\n",
    "print(query_with_context)\n",
    "# now use the LLM to answer the query \n",
    "\n",
    "\n",
    "add_context_to_query(query, context)\n",
    "\n",
    "get_ollama_suggestions(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── .gitignore\n",
      "├── .gitmodules\n",
      "├── LICENSE\n",
      "├── Makefile\n",
      "├── README.md\n",
      "├── TestInput.py\n",
      "├── b\n",
      "    ├── resources\n",
      "    │   ├── 1-node-template.ini\n",
      "    │   ├── 2-nodes-template.ini\n",
      "    │   ├── 20-nodes-template.ini\n",
      "    │   ├── 3-nodes-template.ini\n",
      "    │   ├── 35-nodes-template.ini\n",
      "    │   ├── 4-nodes-n1ql-index-template.ini\n",
      "    │   ├── 4-nodes-n1ql-template.ini\n",
      "    │   ├── 4-nodes-template-KV.ini\n",
      "    │   ├── 4-nodes-template-cbas-multi-cluster.ini\n",
      "    │   ├── 4-nodes-template-cbas.ini\n",
      "    │   ├── 4-nodes-template-sanity.ini\n",
      "    │   ├── 4-nodes-template.ini\n",
      "    │   ├── 5-nodes-bkrs-2clusters.ini\n",
      "    │   ├── 5-nodes-n1ql-index-template.ini\n",
      "    │   ├── 5-nodes-template.ini\n",
      "    │   ├── 6-nodes-template-cbas.ini\n",
      "    │   ├── 6-nodes-template-ce.ini\n",
      "    │   ├── 6-nodes-template-multi-cluster.ini\n",
      "    │   ├── 6-nodes-template-n1ql-xdcr.ini\n",
      "    │   ├── 6-nodes-template-n1ql.ini\n",
      "    │   ├── 6-nodes-template-xdcr.ini\n",
      "    │   ├── 6-nodes-template.ini\n",
      "    │   ├── 7-nodes-template.ini\n",
      "    │   ├── 8-nodes-template-cbas.ini\n",
      "    │   ├── 9-nodes-template.ini\n",
      "    │   ├── capella\n",
      "    │   │   ├── 3-nodes-template.ini\n",
      "    │   │   ├── goldfish-template.ini\n",
      "    │   │   ├── provisioned-template.ini\n",
      "    │   │   └── serverless-template.ini\n",
      "    │   ├── dev-3-nodes.ini\n",
      "    │   ├── dev-4-nodes.ini\n",
      "    │   ├── dev-6-nodes.ini\n",
      "    │   └── luks-nodes.ini\n",
      "    └── testdata.json\n",
      "├── build.gradle\n",
      "├── conf\n",
      "    ├── 2i\n",
      "    │   ├── cgroups_gsi.conf\n",
      "    │   └── durability_aborts.conf\n",
      "    ├── Atomicity\n",
      "    │   ├── basic.conf\n",
      "    │   ├── concurrency_basic.conf\n",
      "    │   ├── crash_test.conf\n",
      "    │   ├── diff_doc_size.conf\n",
      "    │   ├── doc_isolation.conf\n",
      "    │   ├── failover\n",
      "    │   │   ├── py-autofailover.conf\n",
      "    │   │   ├── py-diskautofailover.conf\n",
      "    │   │   └── py-newfailover.conf\n",
      "    │   ├── hooks_basic.conf\n",
      "    │   ├── multi_bucket_basic.conf\n",
      "    │   ├── param_update.conf\n",
      "    │   ├── rebalance\n",
      "    │   │   ├── rebalance_auto_retry.conf\n",
      "    │   │   ├── rebalance_in.conf\n",
      "    │   │   ├── rebalance_in_out.conf\n",
      "    │   │   ├── rebalance_out.conf\n",
      "    │   │   └── swap_rebalance.conf\n",
      "    │   └── transaction_basic.conf\n",
      "    ├── N1qlTransaction\n",
      "    │   ├── basic.conf\n",
      "    │   ├── basic_ephemeral.conf\n",
      "    │   ├── bucket_param.conf\n",
      "    │   ├── collections_failover_crud_on_collections.conf\n",
      "    │   ├── collections_rebalance_with_N1ql_txn.conf\n",
      "    │   ├── concurrency.conf\n",
      "    │   ├── concurrency_multiple_query_nodes.conf\n",
      "    │   ├── different_services.conf\n",
      "    │   ├── memory_quota.conf\n",
      "    │   ├── misc_test.conf\n",
      "    │   ├── multi_bucket.conf\n",
      "    │   ├── negative_testcase.conf\n",
      "    │   ├── os_certify_txns.conf\n",
      "    │   ├── process_crash.conf\n",
      "    │   ├── queries_use_keys.conf\n",
      "    │   ├── test_with_kvtimeout.conf\n",
      "    │   ├── test_with_prepare.conf\n",
      "    │   └── txn_durability_level.conf\n",
      "    ├── bucket\n",
      "    │   ├── bucket_level_durability.conf\n",
      "    │   ├── compaction.conf\n",
      "    │   ├── dgm.conf\n",
      "    │   ├── limits-connections.conf\n",
      "    │   ├── limits-data-size.conf\n",
      "    │   ├── limits-egress.conf\n",
      "    │   ├── limits-ingress.conf\n",
      "    │   ├── limits-ops.conf\n",
      "    │   ├── max_ttl.conf\n",
      "    │   ├── multi_bucket.conf\n",
      "    │   ├── multi_bucket_multi_durability.conf\n",
      "    │   └── replica_update.conf\n",
      "    ├── capella\n",
      "    │   ├── alert-v4-APIs.conf\n",
      "    │   ├── allowedCIDR-v4-APIs.conf\n",
      "    │   ├── appServicesOnOff.conf\n",
      "    │   ├── auditLogExports-v4-APIs.conf\n",
      "    │   ├── azureAutoExpansion-v4-APIs.conf\n",
      "    │   ├── bucket-v4-APIs.conf\n",
      "    │   ├── cluster-v4-APIs.conf\n",
      "    │   ├── clusterOnOff.conf\n",
      "    │   ├── col_v4_API-sanity.conf\n",
      "    │   ├── collection-v4-APIs.conf\n",
      "    │   ├── cp_v4_API-sanity.conf\n",
      "    │   ├── negative_tests.conf\n",
      "    │   ├── onOffSchedule-v4-APIs.conf\n",
      "    │   ├── organization-v4-APIs.conf\n",
      "    │   ├── project-v4-APIs.conf\n",
      "    │   ├── sampleBucket-v4-APIs.conf\n",
      "    │   ├── scope-v4-APIs.conf\n",
      "    │   └── throttle_tests.conf\n",
      "    ├── cas_test\n",
      "    │   └── castest.conf\n",
      "    ├── cbas\n",
      "    │   ├── magma\n",
      "    │   │   ├── py-cbas-collection-failover.conf\n",
      "    │   │   ├── py-cbas-collection-multi-bucket.conf\n",
      "    │   │   ├── py-cbas-collection-rebalance.conf\n",
      "    │   │   └── py-cbas-collection.conf\n",
      "    │   ├── py-cbas-audit.conf\n",
      "    │   ├── py-cbas-backup-restore.conf\n",
      "    │   ├── py-cbas-bucket-operations.conf\n",
      "    │   ├── py-cbas-bug-automation.conf\n",
      "    │   ├── py-cbas-capella-automation.conf\n",
      "    │   ├── py-cbas-cbo.conf\n",
      "    │   ├── py-cbas-cgroup.conf\n",
      "    │   ├── py-cbas-collection-failover.conf\n",
      "    │   ├── py-cbas-collection-rebalance.conf\n",
      "    │   ├── py-cbas-collections.conf\n",
      "    │   ├── py-cbas-error-response.conf\n",
      "    │   ├── py-cbas-external-datasets-AWS-parquet.conf\n",
      "    │   ├── py-cbas-external-links-AWS.conf\n",
      "    │   ├── py-cbas-external-links-azure_blob.conf\n",
      "    │   ├── py-cbas-high-availability.conf\n",
      "    │   ├── py-cbas-ip-address-family.conf\n",
      "    │   ├── py-cbas-metadata-replication.conf\n",
      "    │   ├── py-cbas-multiple_ca.conf\n",
      "    │   ├── py-cbas-os-certify.conf\n",
      "    │   ├── py-cbas-remote-links-datasets.conf\n",
      "    │   ├── py-cbas-secondary-indexes.conf\n",
      "    │   ├── py-cbas-system-event-logs.conf\n",
      "    │   └── py-cbas-udf-management.conf\n",
      "    ├── collections\n",
      "    │   ├── app.conf\n",
      "    │   ├── bucket_flush.conf\n",
      "    │   ├── bucket_param_update.conf\n",
      "    │   ├── bucket_warmup.conf\n",
      "    │   ├── cas.conf\n",
      "    │   ├── collections_auto_retry_failed_rebalance.conf\n",
      "    │   ├── collections_autofailover.conf\n",
      "    │   ├── collections_autoreprovision_0_replica.conf\n",
      "    │   ├── collections_dgm_steady.conf\n",
      "    │   ├── collections_diskautofailover.conf\n",
      "    │   ├── collections_drop_recreate_rebalance.conf\n",
      "    │   ├── collections_failover.conf\n",
      "    │   ├── collections_failover_crud_on_collections.conf\n",
      "    │   ├── collections_failover_crud_on_collections_dgm.conf\n",
      "    │   ├── collections_failover_dgm.conf\n",
      "    │   ├── collections_multinodeautofailover.conf\n",
      "    │   ├── collections_negative_tc.conf\n",
      "    │   ├── collections_network_split.conf\n",
      "    │   ├── collections_quorum_loss_failover.conf\n",
      "    │   ├── collections_rebalance.conf\n",
      "    │   ├── collections_rebalance_crud_on_collections.conf\n",
      "    │   ├── collections_rebalance_crud_on_collections_dgm.conf\n",
      "    │   ├── collections_rebalance_dgm.conf\n",
      "    │   ├── collections_start_stop_tests.conf\n",
      "    │   ├── collections_with_ttl.conf\n",
      "    │   ├── compaction.conf\n",
      "    │   ├── dcp_oso_backfill.conf\n",
      "    │   ├── document_keys.conf\n",
      "    │   ├── durability_failures.conf\n",
      "    │   ├── durability_success.conf\n",
      "    │   ├── process_crash.conf\n",
      "    │   ├── rollback.conf\n",
      "    │   ├── sanity.conf\n",
      "    │   ├── sdk_exception_tests.conf\n",
      "    │   ├── steady_state.conf\n",
      "    │   └── steady_state_compression.conf\n",
      "    ├── columnar\n",
      "    │   ├── columnar_rbac_cloud.conf\n",
      "    │   ├── copy_into_standalone_collection_from_S3.conf\n",
      "    │   ├── copy_to_kv.conf\n",
      "    │   ├── copy_to_s3.conf\n",
      "    │   ├── dynamic_prefixes.conf\n",
      "    │   ├── external_links_datasets_S3.conf\n",
      "    │   ├── goldfish_volume.conf\n",
      "    │   ├── insert_upsert_delete_standalone_collection.conf\n",
      "    │   ├── legacy_cbas\n",
      "    │   │   ├── py-cbas-cbo.conf\n",
      "    │   │   ├── py-cbas-collections.conf\n",
      "    │   │   ├── py-cbas-external-links-AWS.conf\n",
      "    │   │   ├── py-cbas-remote-links-datasets.conf\n",
      "    │   │   ├── py-cbas-secondary-indexes.conf\n",
      "    │   │   ├── py-cbas-standalone-collection-external-link-s3.conf\n",
      "    │   │   └── py-cbas-udf-management.conf\n",
      "    │   ├── on_off.conf\n",
      "    │   ├── onprem\n",
      "    │   │   ├── build_verification_sanity.conf\n",
      "    │   │   ├── columnar_rbac_onprem.conf\n",
      "    │   │   └── copy_to_kv.conf\n",
      "    │   ├── remote_links_datasets.conf\n",
      "    │   ├── sample_sirius_test.conf\n",
      "    │   ├── scaling_operations.conf\n",
      "    │   ├── security.conf\n",
      "    │   └── standalone_collection.conf\n",
      "    ├── dcp\n",
      "    │   └── dcp_new_test.conf\n",
      "    ├── ent_bkrs\n",
      "    │   └── bkrs_transactions.conf\n",
      "    ├── ep_engine\n",
      "    │   ├── basic_ops.conf\n",
      "    │   ├── cas_durability_failures.conf\n",
      "    │   ├── cas_test.conf\n",
      "    │   ├── documentkeys.conf\n",
      "    │   ├── durability_failures.conf\n",
      "    │   ├── durability_success.conf\n",
      "    │   ├── durability_timeouts.conf\n",
      "    │   ├── large_docs.conf\n",
      "    │   ├── ooo_returns.conf\n",
      "    │   ├── process_crash.conf\n",
      "    │   ├── sub_doc_failures.conf\n",
      "    │   ├── sub_doc_success.conf\n",
      "    │   ├── subdoc_xattr.conf\n",
      "    │   ├── syncwrite_failures_with_creates.conf\n",
      "    │   ├── syncwrite_failures_with_deletes.conf\n",
      "    │   ├── syncwrite_failures_with_upserts.conf\n",
      "    │   ├── tombstones_a.conf\n",
      "    │   ├── tombstones_b.conf\n",
      "    │   └── xattr_tests.conf\n",
      "    ├── eventing\n",
      "    │   ├── eventing_cgroup.conf\n",
      "    │   └── eventing_durability_aborts.conf\n",
      "    ├── failover\n",
      "    │   ├── concurrent_failovers.conf\n",
      "    │   ├── failover_with_durability.conf\n",
      "    │   ├── fast_failover.conf\n",
      "    │   ├── py-auto-failover-server-stop.conf\n",
      "    │   ├── py-autofailover-buckets.conf\n",
      "    │   ├── py-autofailover-firewall.conf\n",
      "    │   ├── py-autofailover-memcached.conf\n",
      "    │   ├── py-autofailover-network-split.conf\n",
      "    │   ├── py-autofailover.conf\n",
      "    │   ├── py-multinodefailover.conf\n",
      "    │   ├── py-multinodefailover_rebalance.conf\n",
      "    │   ├── py-negativefailover.conf\n",
      "    │   ├── py-newfailover.conf\n",
      "    │   └── py-servergroup-failover.conf\n",
      "    ├── fts\n",
      "    │   └── fts_durability_aborts.conf\n",
      "    ├── guardrails\n",
      "    │   ├── bucket_guardrails.conf\n",
      "    │   ├── disk_usage_guardrails.conf\n",
      "    │   ├── guardrails_with_migration.conf\n",
      "    │   ├── guardrails_with_upgrades.conf\n",
      "    │   ├── max_data_guardrails.conf\n",
      "    │   └── rr_guardrails.conf\n",
      "    ├── history_retention\n",
      "    │   ├── rebalance_test.conf\n",
      "    │   └── steady_state.conf\n",
      "    ├── magma\n",
      "    │   ├── 10gb_per_vbucket.conf\n",
      "    │   ├── basic_cruds_del.conf\n",
      "    │   ├── basic_cruds_get.conf\n",
      "    │   ├── basic_cruds_low_RAM.conf\n",
      "    │   ├── basic_cruds_set.conf\n",
      "    │   ├── basic_cruds_upsert.conf\n",
      "    │   ├── basic_upsert_delete.conf\n",
      "    │   ├── cdc_magma_failures.conf\n",
      "    │   ├── cdc_steady_state.conf\n",
      "    │   ├── collections_failover.conf\n",
      "    │   ├── collections_failover_crud_on_collections.conf\n",
      "    │   ├── collections_rebalance.conf\n",
      "    │   ├── collections_rebalance_crud_on_collections.conf\n",
      "    │   ├── compaction.conf\n",
      "    │   ├── crash_recovery.conf\n",
      "    │   ├── crash_recovery_low_RAM.conf\n",
      "    │   ├─\n",
      "Created 28118 chunks\n",
      "\n",
      "First chunk sample:\n",
      "├── .gitignore\n",
      "├── .gitmodules\n",
      "├── LICENSE\n",
      "├── Makefile\n",
      "├── README.md\n",
      "├── TestInput.py\n",
      "├── b\n",
      "    ├── resources\n",
      "    │   ├── 1-node-template.ini\n",
      "    │   ├── 2-nodes-template.ini\n",
      "    │   ├── 20-nodes-tem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "text = load_text(\"DataLake/TAF.txt\")\n",
    "# Create chunks with 500 char window and 100 char overlap\n",
    "data_chunks = chunk_text(text, window_size=1000, overlap=200)\n",
    "\n",
    "print(f\"Created {len(data_chunks)} chunks\")\n",
    "print(f\"\\nFirst chunk sample:\\n{data_chunks[0][:200]}...\")\n",
    "\n",
    "model = load_model(\"nomic-ai/CodeRankEmbed\")\n",
    "\n",
    "embeddings = embed_chunks(data_chunks,model)\n",
    "print(embeddings)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "\n",
    "vector_store = create_vector_store(embeddings)\n",
    "store_vector_store(vector_store=vector_store, file_path=\"VectorStore/TAF_HNSW.pkl\")\n",
    "\n",
    "vector_store = load_vector_store(file_path=\"VectorStore/TAF_HNSW.pkl\")\n",
    "query = \"what's the use of check history_retention function in magma?\"\n",
    "context = query_vector_store(query, vector_store, model, data_chunks)\n",
    "print(context)\n",
    "\n",
    "query_with_context = add_context_to_query(query, context)\n",
    "print(query_with_context)\n",
    "# now use the LLM to answer the query \n",
    "\n",
    "\n",
    "add_context_to_query(query, context)\n",
    "\n",
    "get_ollama_suggestions(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oteMachineShellConnection(self.server)\n",
      " 45 |         output, error = remote_client.execute_command(self.command)\n",
      " 46 |         print(self.server.ip)\n",
      " 47 |         print(\"\\n\".join(output))\n",
      " 48 |         print(\"\\n\".join(error))\n",
      " 49 |         remote_client.disconnect()\n",
      " 50 | \n",
      " 51 | \n",
      " 52 | class ScriptRunner(object):\n",
      " 53 |     def __init__(self, server, script):\n",
      " 54 |         self.server = server\n",
      " 55 |         with open(script) as  f:\n",
      " 56 |             self.script_content = f.read()\n",
      " 57 |         self.script_name = \"/tmp/\" + str(uuid.uuid4())\n",
      " 58 | \n",
      " 59 |     def run(self):\n",
      " 60 |         remote_client = RemoteMachineShellConnection(self.server)\n",
      " 61 |         remote_client.create_file(self.script_name, self.script_content)\n",
      " 62 |         output, error = remote_client.execute_command(\n",
      " 63 |             \"chmod 777 {0} ; {0} ; rm -f {0}\".format(self.script_name))\n",
      " 64 |         print(self.server.ip)\n",
      " 65 |         print(\"\\n\".join(output))\n",
      " 66 |         print(\"\\n\".join(error))\n",
      " 67 |         remote\n",
      "ocess\n",
      " 122 |         else:\n",
      " 123 |             processes = self.remote_shell.get_running_processes()\n",
      " 124 |             for process in processes:\n",
      " 125 |                 if process.name == process_name:\n",
      " 126 |                     return process\n",
      " 127 |                 elif process_name in process.args:\n",
      " 128 |                     return process\n",
      " 129 |             return None\n",
      " 130 | \n",
      " 131 | \n",
      " 132 | class RemoteMachineShellConnection:\n",
      " 133 |     connections = 0\n",
      " 134 |     disconnections = 0\n",
      " 135 | \n",
      " 136 |     def __init__(self, serverInfo):\n",
      " 137 |         RemoteMachineShellConnection.connections += 1\n",
      " 138 |         self.jsch = None\n",
      " 139 |         self.session = None\n",
      " 140 |         self.input = TestInput.TestInputParser.get_test_input(sys.argv)\n",
      " 141 |         self.log = logger.get(\"infra\")\n",
      " 142 |         self.test_log = logger.get(\"test\")\n",
      " 143 | \n",
      " 144 |         self.ip = serverInfo.ip\n",
      " 145 |         self.username = serverInfo.ssh_username\n",
      " 146 |         self.password = serverInfo.ssh_password\n",
      "ShellConnection\n",
      " 8 | from BucketOperations_Rest import BucketHelper as BucketHelperRest\n",
      " 9 | from bucket import Bucket\n",
      "10 | \n",
      "11 | \n",
      "12 | class BucketHelper(BucketHelperRest):\n",
      "13 |     def __init__(self, server, username=\"Administrator\", password=\"password\"):\n",
      "14 |         super(BucketHelper, self).__init__(server)\n",
      "15 |         self.server = server\n",
      "16 |         self.username = username\n",
      "17 |         self.password = password\n",
      "18 |         self.cb_cli = None\n",
      "19 | \n",
      "20 |     def __use_shell(self, cli_function):\n",
      "21 |         def wrapper():\n",
      "22 |             shell = RemoteMachineShellConnection(self.server)\n",
      "23 |             self.cb_cli = CbCli(shell, self.username, self.password)\n",
      "24 |             try:\n",
      "25 |                 output = cli_function()\n",
      "26 |             except Exception as e:\n",
      "27 |                 shell.disconnect()\n",
      "28 |                 raise e\n",
      "29 |             shell.disconnect()\n",
      "30 |             return output\n",
      "31 |         return wrapper\n",
      "32 | \n",
      "33 |     @__use_shell\n",
      "34 |     def create_buck\n",
      "RemoteMachineShellConnection(self.servers[0])\n",
      "  83 |         info = shell.extract_remote_info().type.lower()\n",
      "  84 |         self.root_path = Linux.ROOT_PATH\n",
      "  85 |         self.wget = \"wget\"\n",
      "  86 |         self.os_name = \"linux\"\n",
      "  87 |         self.tmp_path = \"/tmp/\"\n",
      "  88 |         self.long_help_flag = \"--help\"\n",
      "  89 |         self.short_help_flag = \"-h\"\n",
      "  90 |         self.cygwin_bin_path = \"\"\n",
      "  91 |         self.enable_firewal = False\n",
      "  92 |         self.rfc3339_date = \"date +%s --date='{0} seconds' | \".format(self.replace_ttl_with) + \\\n",
      "  93 |                                 \"xargs -I {} date --date='@{}' --rfc-3339=seconds | \"\\\n",
      "  94 |                                 \"sed 's/ /T/'\"\n",
      "  95 |         self.seconds_with_ttl = \"date +%s --date='{0} seconds'\".format(self.replace_ttl_with)\n",
      "  96 |         if info == Linux.NAME:\n",
      "  97 |             if self.nonroot:\n",
      "  98 |                 base_path = \"/home/%s\" % self.cluster.master.ssh_username\n",
      "  99 |                 self.database_path = \"%s%s\" \n",
      "tils.capella_utils.dedicated import CapellaUtils\n",
      "  11 | from TestInput import TestInputSingleton\n",
      "  12 | from platform_utils.remote.remote_util import RemoteMachineShellConnection\n",
      "  13 | \n",
      "  14 | \n",
      "  15 | class ServerInfo:\n",
      "  16 |     def __init__(self,\n",
      "  17 |                  ip,\n",
      "  18 |                  port,\n",
      "  19 |                  ssh_username,\n",
      "  20 |                  ssh_password,\n",
      "  21 |                  memcached_port,\n",
      "  22 |                  ssh_key=''):\n",
      "  23 |         self.ip = ip\n",
      "  24 |         self.ssh_username = ssh_username\n",
      "  25 |         self.ssh_password = ssh_password\n",
      "  26 |         self.port = port\n",
      "  27 |         self.ssh_key = ssh_key\n",
      "  28 |         self.memcached_port = memcached_port\n",
      "  29 |         self.type = None\n",
      "  30 |         self.remote_info = None\n",
      "  31 | \n",
      "  32 | \n",
      "  33 | class SecurityTest(SecurityBase):\n",
      "  34 |     SLAVE_HOST = ServerInfo('127.0.0.1', 22, 'root', 'couchbase', 18091)\n",
      "  35 | \n",
      "  36 |     def setUp(self):\n",
      "  37 |         try:\n",
      "  38 |             SecurityBa\n",
      "\n",
      "Query: How to use RemoteShellConnection in test and give me usage\n",
      "Context: oteMachineShellConnection(self.server)\n",
      " 45 |         output, error = remote_client.execute_command(self.command)\n",
      " 46 |         print(self.server.ip)\n",
      " 47 |         print(\"\\n\".join(output))\n",
      " 48 |         print(\"\\n\".join(error))\n",
      " 49 |         remote_client.disconnect()\n",
      " 50 | \n",
      " 51 | \n",
      " 52 | class ScriptRunner(object):\n",
      " 53 |     def __init__(self, server, script):\n",
      " 54 |         self.server = server\n",
      " 55 |         with open(script) as  f:\n",
      " 56 |             self.script_content = f.read()\n",
      " 57 |         self.script_name = \"/tmp/\" + str(uuid.uuid4())\n",
      " 58 | \n",
      " 59 |     def run(self):\n",
      " 60 |         remote_client = RemoteMachineShellConnection(self.server)\n",
      " 61 |         remote_client.create_file(self.script_name, self.script_content)\n",
      " 62 |         output, error = remote_client.execute_command(\n",
      " 63 |             \"chmod 777 {0} ; {0} ; rm -f {0}\".format(self.script_name))\n",
      " 64 |         print(self.server.ip)\n",
      " 65 |         print(\"\\n\".join(output))\n",
      " 66 |         print(\"\\n\".join(error))\n",
      " 67 |         remote\n",
      "ocess\n",
      " 122 |         else:\n",
      " 123 |             processes = self.remote_shell.get_running_processes()\n",
      " 124 |             for process in processes:\n",
      " 125 |                 if process.name == process_name:\n",
      " 126 |                     return process\n",
      " 127 |                 elif process_name in process.args:\n",
      " 128 |                     return process\n",
      " 129 |             return None\n",
      " 130 | \n",
      " 131 | \n",
      " 132 | class RemoteMachineShellConnection:\n",
      " 133 |     connections = 0\n",
      " 134 |     disconnections = 0\n",
      " 135 | \n",
      " 136 |     def __init__(self, serverInfo):\n",
      " 137 |         RemoteMachineShellConnection.connections += 1\n",
      " 138 |         self.jsch = None\n",
      " 139 |         self.session = None\n",
      " 140 |         self.input = TestInput.TestInputParser.get_test_input(sys.argv)\n",
      " 141 |         self.log = logger.get(\"infra\")\n",
      " 142 |         self.test_log = logger.get(\"test\")\n",
      " 143 | \n",
      " 144 |         self.ip = serverInfo.ip\n",
      " 145 |         self.username = serverInfo.ssh_username\n",
      " 146 |         self.password = serverInfo.ssh_password\n",
      "ShellConnection\n",
      " 8 | from BucketOperations_Rest import BucketHelper as BucketHelperRest\n",
      " 9 | from bucket import Bucket\n",
      "10 | \n",
      "11 | \n",
      "12 | class BucketHelper(BucketHelperRest):\n",
      "13 |     def __init__(self, server, username=\"Administrator\", password=\"password\"):\n",
      "14 |         super(BucketHelper, self).__init__(server)\n",
      "15 |         self.server = server\n",
      "16 |         self.username = username\n",
      "17 |         self.password = password\n",
      "18 |         self.cb_cli = None\n",
      "19 | \n",
      "20 |     def __use_shell(self, cli_function):\n",
      "21 |         def wrapper():\n",
      "22 |             shell = RemoteMachineShellConnection(self.server)\n",
      "23 |             self.cb_cli = CbCli(shell, self.username, self.password)\n",
      "24 |             try:\n",
      "25 |                 output = cli_function()\n",
      "26 |             except Exception as e:\n",
      "27 |                 shell.disconnect()\n",
      "28 |                 raise e\n",
      "29 |             shell.disconnect()\n",
      "30 |             return output\n",
      "31 |         return wrapper\n",
      "32 | \n",
      "33 |     @__use_shell\n",
      "34 |     def create_buck\n",
      "RemoteMachineShellConnection(self.servers[0])\n",
      "  83 |         info = shell.extract_remote_info().type.lower()\n",
      "  84 |         self.root_path = Linux.ROOT_PATH\n",
      "  85 |         self.wget = \"wget\"\n",
      "  86 |         self.os_name = \"linux\"\n",
      "  87 |         self.tmp_path = \"/tmp/\"\n",
      "  88 |         self.long_help_flag = \"--help\"\n",
      "  89 |         self.short_help_flag = \"-h\"\n",
      "  90 |         self.cygwin_bin_path = \"\"\n",
      "  91 |         self.enable_firewal = False\n",
      "  92 |         self.rfc3339_date = \"date +%s --date='{0} seconds' | \".format(self.replace_ttl_with) + \\\n",
      "  93 |                                 \"xargs -I {} date --date='@{}' --rfc-3339=seconds | \"\\\n",
      "  94 |                                 \"sed 's/ /T/'\"\n",
      "  95 |         self.seconds_with_ttl = \"date +%s --date='{0} seconds'\".format(self.replace_ttl_with)\n",
      "  96 |         if info == Linux.NAME:\n",
      "  97 |             if self.nonroot:\n",
      "  98 |                 base_path = \"/home/%s\" % self.cluster.master.ssh_username\n",
      "  99 |                 self.database_path = \"%s%s\" \n",
      "tils.capella_utils.dedicated import CapellaUtils\n",
      "  11 | from TestInput import TestInputSingleton\n",
      "  12 | from platform_utils.remote.remote_util import RemoteMachineShellConnection\n",
      "  13 | \n",
      "  14 | \n",
      "  15 | class ServerInfo:\n",
      "  16 |     def __init__(self,\n",
      "  17 |                  ip,\n",
      "  18 |                  port,\n",
      "  19 |                  ssh_username,\n",
      "  20 |                  ssh_password,\n",
      "  21 |                  memcached_port,\n",
      "  22 |                  ssh_key=''):\n",
      "  23 |         self.ip = ip\n",
      "  24 |         self.ssh_username = ssh_username\n",
      "  25 |         self.ssh_password = ssh_password\n",
      "  26 |         self.port = port\n",
      "  27 |         self.ssh_key = ssh_key\n",
      "  28 |         self.memcached_port = memcached_port\n",
      "  29 |         self.type = None\n",
      "  30 |         self.remote_info = None\n",
      "  31 | \n",
      "  32 | \n",
      "  33 | class SecurityTest(SecurityBase):\n",
      "  34 |     SLAVE_HOST = ServerInfo('127.0.0.1', 22, 'root', 'couchbase', 18091)\n",
      "  35 | \n",
      "  36 |     def setUp(self):\n",
      "  37 |         try:\n",
      "  38 |             SecurityBa\n",
      "\n",
      "<think>\n",
      "Okay, I need to figure out how to use RemoteShellConnection based on the provided code snippets. Let me start by looking through the context given.\n",
      "\n",
      "I see that RemoteMachineShellConnection is a class defined in lines 132-146 and elsewhere. It's used for connecting to remote machines via SSH. The __init__ method initializes it with server info, including IP, username, and password.\n",
      "\n",
      "Looking at how it's used in other parts of the code, like in line 45 where a client executes a command and prints output and error. Another example is in the ScriptRunner class where they create a file on the remote machine, run a script, and then disconnect.\n",
      "\n",
      "So, to use RemoteShellConnection, I should probably:\n",
      "\n",
      "1. Import the necessary modules.\n",
      "2. Create an instance by providing server info (IP, username, password).\n",
      "3. Use methods like execute_command to run commands.\n",
      "4. Handle output and errors appropriately.\n",
      "5. Disconnect after use to manage resources.\n",
      "\n",
      "I might also need to handle exceptions or ensure connections are closed properly, maybe using try-finally blocks or context managers if available.\n",
      "\n",
      "Let me outline the steps I think are needed:\n",
      "\n",
      "- Import RemoteMachineShellConnection from its module.\n",
      "- Create a ServerInfo object with the target IP, username, and password.\n",
      "- Instantiate RemoteMachineShellConnection with this server info.\n",
      "- Use execute_command to run the desired command.\n",
      "- Capture output and errors for logging or processing.\n",
      "- Disconnect after finishing.\n",
      "\n",
      "I should also check if there are any specific parameters or flags needed when initializing, but from the context, it seems the constructor requires serverInfo which includes all necessary details.\n",
      "\n",
      "Potential issues I might face: connection timeouts, authentication failures, or handling SSH keys if required. But based on the code, password-based auth is supported.\n",
      "\n",
      "I think that's a good start. Now, let me put together an example of how to use RemoteShellConnection in a test.\n",
      "</think>\n",
      "\n",
      "To utilize `RemoteMachineShellConnection` effectively in your tests, follow these steps:\n",
      "\n",
      "### 1. Import Necessary Modules\n",
      "Ensure you import the `RemoteMachineShellConnection` class from its respective module.\n",
      "\n",
      "```python\n",
      "from platform_utils.remote.remote_util import RemoteMachineShellConnection\n",
      "```\n",
      "\n",
      "### 2. Define Server Information\n",
      "Create a `ServerInfo` object with the required details for connecting to the remote machine.\n",
      "\n",
      "```python\n",
      "server_info = ServerInfo(\n",
      "    ip='remote_machine_ip',\n",
      "    port=22,\n",
      "    ssh_username='username',\n",
      "    ssh_password='password'\n",
      ")\n",
      "```\n",
      "\n",
      "### 3. Establish Remote Connection\n",
      "Instantiate `RemoteMachineShellConnection` using the server information.\n",
      "\n",
      "```python\n",
      "with RemoteMachineShellConnection(server_info) as shell:\n",
      "    # Execute commands within this block to ensure proper cleanup\n",
      "    pass\n",
      "```\n",
      "\n",
      "Using a `with` statement ensures that the connection is properly closed after execution, even if an error occurs.\n",
      "\n",
      "### 4. Execute Commands\n",
      "Within the context manager, execute the desired command using the `execute_command` method.\n",
      "\n",
      "```python\n",
      "_, stdout, stderr = shell.execute_command('ls -l')\n",
      "print(\"Output:\", stdout.read())\n",
      "print(\"Error:\", stderr.read())\n",
      "```\n",
      "\n",
      "The `execute_command` method returns three file-like objects: stdin, stdout, and stderr. You can use these to capture command outputs.\n",
      "\n",
      "### 5. Handle Edge Cases\n",
      "Always ensure that the connection is closed properly to avoid resource leaks. Using a context manager (`with` statement) handles this automatically.\n",
      "\n",
      "### Complete Example\n",
      "\n",
      "Here's a complete example integrating all the steps:\n",
      "\n",
      "```python\n",
      "from platform_utils.remote.remote_util import RemoteMachineShellConnection\n",
      "from TestInput import TestInputSingleton\n",
      "\n",
      "# Initialize Test Input Singleton if necessary\n",
      "TestInput = TestInputSingleton()\n",
      "\n",
      "def test_remote_connection():\n",
      "    # Define server information\n",
      "    server_info = ServerInfo(\n",
      "        ip='remote_machine_ip',\n",
      "        port=22,\n",
      "        ssh_username='username',\n",
      "        ssh_password='password'\n",
      "    )\n",
      "\n",
      "    # Use the context manager to handle connection and cleanup\n",
      "    with RemoteMachineShellConnection(server_info) as shell:\n",
      "        # Execute a command\n",
      "        _, stdout, stderr = shell.execute_command('ls -l')\n",
      "\n",
      "        # Read output and errors\n",
      "        print(\"Output:\", stdout.read().decode())\n",
      "        print(\"Error:\", stderr.read().decode())\n",
      "\n",
      "        # Check for errors\n",
      "        if stderr.read():\n",
      "            raise Exception(f\"Command execution failed with error: {stderr}\")\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    test_remote_connection()\n",
      "```\n",
      "\n",
      "### Notes:\n",
      "- **Resource Management**: Using a `with` statement ensures that the connection is closed automatically, even if an exception occurs.\n",
      "- **Output Handling**: The stdout and stderr are returned as file-like objects. Reading their content using `.read()` gives the output. Decoding might be necessary depending on your system's locale.\n",
      "- **Error Handling**: Always check for errors in command execution. If `stderr` is not empty, it indicates a failure.\n",
      "\n",
      "By following these steps, you can effectively use `RemoteMachineShellConnection` to execute commands and manage remote resources in your tests."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Streaming complete'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How to use RemoteShellConnection in test and give me usage\"\n",
    "context = query_vector_store(query, vector_store, model, data_chunks)\n",
    "print(context)\n",
    "\n",
    "query_with_context = add_context_to_query(query, context)\n",
    "print(query_with_context)\n",
    "# now use the LLM to answer the query \n",
    "\n",
    "\n",
    "add_context_to_query(query, context)\n",
    "\n",
    "get_ollama_suggestions(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
